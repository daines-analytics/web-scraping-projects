{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping of Machine Learning Mastery Blog Entries Using Python and BeautifulSoup\n",
    "### David Lowe\n",
    "### January 6, 2019\n",
    "\n",
    "SUMMARY: The purpose of this project is to practice web scraping by extracting specific pieces of information from a website. The web scraping code was written in Python 3 and leverages the BeautifulSoup module.\n",
    "\n",
    "INTRODUCTION: Dr. Jason Brownlee’s Machine Learning Mastery hosts its tutorial lessons at https://machinelearningmastery.com/blog. The purpose of this exercise is to practice web scraping using Scrapy by gathering the blog entries from Machine Learning Mastery’s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\n",
    "\n",
    "Starting URLs: https://machinelearningmastery.com/blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "from datetime import datetime\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "from bs4 import BeautifulSoup\n",
    "from random import randint\n",
    "from time import sleep\n",
    "\n",
    "startTimeScript = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the email notification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_notify(msg_text):\n",
    "    sender = \"luozhi2488@gmail.com\"\n",
    "    receiver = \"dave@contactdavidlowe.com\"\n",
    "    with open('../email_credential.txt') as f:\n",
    "        password = f.readline()\n",
    "        f.close()\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(msg_text)\n",
    "    msg['Subject'] = 'Notification from Python Script'\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = receiver\n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    server.starttls()\n",
    "    server.login(sender, password)\n",
    "    server.send_message(msg)\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_notify(\"The web scraping process has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the necessary parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully accessed the web page: https://machinelearningmastery.com/blog\n"
     ]
    }
   ],
   "source": [
    "# Specifying the URL of desired web page to be scrapped\n",
    "starting_url = \"https://machinelearningmastery.com/blog\"\n",
    "# website_url = \"https://papers.nips.cc\"\n",
    "\n",
    "# Creating an html document from the URL\n",
    "uastring = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.80 Safari/537.36\"\n",
    "req = urllib.request.Request(\n",
    "    starting_url,\n",
    "    data=None,\n",
    "    headers={'User-Agent': uastring}\n",
    ")\n",
    "\n",
    "try:\n",
    "    session = urllib.request.urlopen(req)\n",
    "except HTTPError as e:\n",
    "    print('The server could not serve up the page!')\n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "except URLError as e:\n",
    "    print('The server could not be reached!')\n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    webpage = BeautifulSoup(session.read(), 'html5lib')\n",
    "except AttributeError as e:\n",
    "    print('Page title could not be found - Might indicate problems!')\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    print('Successfully accessed the web page: ' + starting_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the Scraping and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/2/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/3/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/4/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/5/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/6/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/7/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/8/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/9/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/10/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/11/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/12/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/13/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/14/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/15/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/16/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/17/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/18/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/19/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/20/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/21/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/22/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/23/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/24/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/25/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/26/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/27/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/28/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/29/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/30/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/31/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/32/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/33/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/34/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/35/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/36/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/37/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/38/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/39/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/40/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/41/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/42/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/43/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/44/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/45/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/46/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/47/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/48/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/49/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/50/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/51/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/52/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/53/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/54/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/55/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/56/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/57/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/58/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/59/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/60/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/61/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/62/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/63/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/64/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/65/\n",
      "Waited 4 seconds to retrieve the next URL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/66/\n",
      "Waited 4 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/67/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/68/\n",
      "Waited 5 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/69/\n",
      "Waited 3 seconds to retrieve the next URL.\n",
      "Successfully accessed the web page: https://machinelearningmastery.com/blog/page/70/\n"
     ]
    }
   ],
   "source": [
    "email_notify(\"The web page loading and item extraction process has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))\n",
    "\n",
    "# Setting up a dataframe to capture the records\n",
    "df = pd.DataFrame(columns=['blog_title','blog_url','date','author','summary'])\n",
    "i = 0\n",
    "\n",
    "article_list = webpage.find_all('article')\n",
    "\n",
    "done = False\n",
    "\n",
    "while not done :\n",
    "    for article_item in article_list:\n",
    "\n",
    "        blog_title = \"[Not Found]\"\n",
    "        blog_url = \"[Not Found]\"\n",
    "        date = \"[Not Found]\"\n",
    "        author = \"[Not Found]\"\n",
    "        summary = \"[Not Found]\"\n",
    "\n",
    "        blog_title = article_item.header.h2.string\n",
    "        blog_url = article_item.a[\"href\"]\n",
    "        date = article_item.abbr.string\n",
    "        author = article_item.find(class_=\"fn\").a.string\n",
    "        summary = article_item.section.p.string\n",
    "        df.loc[i] = [blog_title,blog_url,date,author,summary]\n",
    "        i = i + 1\n",
    "#         print(blog_title,blog_url,date,author,summary)\n",
    "\n",
    "    next_page_css = webpage.find(class_=\"next page-numbers\")\n",
    "\n",
    "    if next_page_css != None :\n",
    "        next_page_url = next_page_css[\"href\"]\n",
    "\n",
    "        # Adding random wait time so we do not hammer the website needlessly\n",
    "        waitTime = randint(3,5)\n",
    "        sleep(waitTime)\n",
    "        print(\"Waited \" + str(waitTime) + \" seconds to retrieve the next URL.\")\n",
    "        req = urllib.request.Request(\n",
    "            next_page_url,\n",
    "            data=None,\n",
    "            headers={'User-Agent': uastring}\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            session = urllib.request.urlopen(req)\n",
    "        except HTTPError as e:\n",
    "            print('The server could not serve up the page!')\n",
    "            print(e)\n",
    "            sys.exit(1)\n",
    "        except URLError as e:\n",
    "            print('The server could not be reached!')\n",
    "            print(e)\n",
    "            sys.exit(1)\n",
    "\n",
    "        try:\n",
    "            webpage = BeautifulSoup(session.read(), 'html5lib')\n",
    "        except AttributeError as e:\n",
    "            print('Page title could not be found - Might indicate problems!')\n",
    "            sys.exit(1)\n",
    "        else:\n",
    "            print('Successfully accessed the web page: ' + next_page_url)\n",
    "            article_list = webpage.find_all('article')\n",
    "    else :\n",
    "        done = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing Data and Producing Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for the script: 0:06:06.208846\n"
     ]
    }
   ],
   "source": [
    "out_file = df.to_json(orient='records')\n",
    "with open('web-scraping-py-bsoup-nips-proceedings.json', 'w') as f:\n",
    "    f.write(out_file)\n",
    "email_notify(\"The web scraping process has completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))\n",
    "print ('Total time for the script:',(datetime.now() - startTimeScript))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
