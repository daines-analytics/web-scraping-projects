{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping of File Download Using Python and BeautifulSoup\n",
    "### David Lowe\n",
    "### April 14, 2019\n",
    "\n",
    "SUMMARY: The purpose of this project is to practice web scraping by extracting specific pieces of information from a website. The web scraping python code leverages the BeautifulSoup module.\n",
    "\n",
    "INTRODUCTION: On occasions I have a need to download a batch of documents off a single web page without clicking on the download link one at a time. This web scraping script will automatically traverse through the entire web page and collect all links to the PDF documents. The script will also download the PDF documents as part of the scraping process.\n",
    "\n",
    "Starting URLs: https://www.knime.com/about/events/knime-spring-summit-2019-berlin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "from datetime import datetime\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "from bs4 import BeautifulSoup\n",
    "from random import randint\n",
    "from time import sleep\n",
    "\n",
    "startTimeScript = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the email notification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_notify(msg_text):\n",
    "    sender = os.environ.get('MAIL_USERNAME')\n",
    "    password = os.environ.get('MAIL_PASSWORD')\n",
    "    receiver = os.environ.get('RECEIVER_MAIL')\n",
    "    if sender==None or password==None or receiver==None :\n",
    "        sys.exit(\"Incomplete email setup info. Script Processing Aborted!!!\")\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(msg_text)\n",
    "    msg['Subject'] = 'Notification from Python Web Scraping Script'\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = receiver\n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    server.starttls()\n",
    "    server.login(sender, password)\n",
    "    server.send_message(msg)\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_notify(\"The web scraping process has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the necessary parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully accessed the web page: https://www.knime.com/about/events/knime-spring-summit-2019-berlin\n"
     ]
    }
   ],
   "source": [
    "# Specifying the URL of desired web page to be scrapped\n",
    "starting_url = \"https://www.knime.com/about/events/knime-spring-summit-2019-berlin\"\n",
    "website_url = \"https://www.knime.com\"\n",
    "\n",
    "# Creating an html document from the URL\n",
    "uastring = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.80 Safari/537.36\"\n",
    "req = urllib.request.Request(\n",
    "    starting_url,\n",
    "    data=None,\n",
    "    headers={'User-Agent': uastring}\n",
    ")\n",
    "\n",
    "try:\n",
    "    session = urllib.request.urlopen(req)\n",
    "except HTTPError as e:\n",
    "    print('The server could not serve up the web page!')\n",
    "    sys.exit(\"Script Processing Aborted!!!\")\n",
    "except URLError as e:\n",
    "    print('The server could not be reached!')\n",
    "    sys.exit(\"Script Processing Aborted!!!\")\n",
    "\n",
    "try:\n",
    "    webpage = BeautifulSoup(session.read(), 'html5lib')\n",
    "    main_title = webpage.body.h2\n",
    "except AttributeError as e:\n",
    "    print('Page title could not be found - Might indicate problems!')\n",
    "    sys.exit(\"Script Processing Aborted!!!\")\n",
    "else:\n",
    "    print('Successfully accessed the web page: ' + starting_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the Scraping and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_notify(\"The web page loading and item extraction process has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting 5 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/01_opening_mb_final.pdf as 01_opening_mb_final.pdf\n",
      "Waiting 3 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/02_software-edu-partner-community_tg_final.pdf as 02_software-edu-partner-community_tg_final.pdf\n",
      "Waiting 6 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/20190320_Knime_WienEnergie.pdf as 20190320_Knime_WienEnergie.pdf\n",
      "Waiting 4 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/20190320_knime_summit_tobiphilippskatja_matthias_final_novideo.pdf as 20190320_knime_summit_tobiphilippskatja_matthias_final_novideo.pdf\n",
      "Waiting 7 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/02a_01_rewe_feature_generation_at_knime_spring_summit_2019_canbepublished.pdf as 02a_01_rewe_feature_generation_at_knime_spring_summit_2019_canbepublished.pdf\n",
      "Waiting 4 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/02a_02_hesso_industrialization_of_rice_grain_recognition_canbepublished.pdf as 02a_02_hesso_industrialization_of_rice_grain_recognition_canbepublished.pdf\n",
      "Waiting 3 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/02a_03_arcelik_knime_summit_20032019_v4_canbepublished.pdf as 02a_03_arcelik_knime_summit_20032019_v4_canbepublished.pdf\n",
      "Waiting 8 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/01_scott_morrison_brendan_doherty_seagate_technology_knime_conference_berlin_march_2019_final_for_pdf.pdf as 01_scott_morrison_brendan_doherty_seagate_technology_knime_conference_berlin_march_2019_final_for_pdf.pdf\n",
      "Waiting 8 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/01_gl_whatsnewindeployment.pdf as 01_gl_whatsnewindeployment.pdf\n",
      "Waiting 7 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/01_gl_whatsnewindeployment.pdf as 01_gl_whatsnewindeployment.pdf\n",
      "Waiting 7 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/02_20190208_predictive_modelling_disability.pdf as 02_20190208_predictive_modelling_disability.pdf\n",
      "Waiting 5 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/190320_knime_summit_published.pdf as 190320_knime_summit_published.pdf\n",
      "Waiting 6 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/the_knime_show_final.pdf as the_knime_show_final.pdf\n",
      "Waiting 5 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/kimble_aswin_verhoeven_190321.pdf as kimble_aswin_verhoeven_190321.pdf\n",
      "Waiting 7 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/03_bfr_20190321_knime-summit_mf_e.pdf as 03_bfr_20190321_knime-summit_mf_e.pdf\n",
      "Waiting 3 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/201903_knime_summit_lbbw_bilanzanalyse_final.pdf as 201903_knime_summit_lbbw_bilanzanalyse_final.pdf\n",
      "Waiting 3 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/01_jf_knime_server_in_action_-_jf_final.pdf as 01_jf_knime_server_in_action_-_jf_final.pdf\n",
      "Waiting 6 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/02_telekom_final.pdf as 02_telekom_final.pdf\n",
      "Waiting 5 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/04_pape_tui_infotec_knime_summit_spring_2019_final.pdf as 04_pape_tui_infotec_knime_summit_spring_2019_final.pdf\n",
      "Waiting 5 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/01_pw_ia_scalability_final.pdf as 01_pw_ia_scalability_final.pdf\n",
      "Waiting 4 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/02_philoverview_final_compressed.pdf as 02_philoverview_final_compressed.pdf\n",
      "Waiting 7 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/data_prep_v7_knime_summit_b-2019_dean.pdf as data_prep_v7_knime_summit_b-2019_dean.pdf\n",
      "Waiting 3 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/openms_seqan_knimesummit_03_19.pdf as openms_seqan_knimesummit_03_19.pdf\n",
      "Waiting 5 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/20190322_aaa_iiot_workshop_1.pdf as 20190322_aaa_iiot_workshop_1.pdf\n",
      "Waiting 4 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/dl_workshop_19.pdf as dl_workshop_19.pdf\n",
      "Waiting 5 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/server_summit_workshop_publish.pdf as server_summit_workshop_publish.pdf\n",
      "Waiting 8 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/20190322_knime_image_processing_workshop.pdf as 20190322_knime_image_processing_workshop.pdf\n",
      "Waiting 4 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/01_intro.pdf as 01_intro.pdf\n",
      "Waiting 5 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/matched_molecular_pairs_analysis.pdf as matched_molecular_pairs_analysis.pdf\n",
      "Waiting 3 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/guided_analytics_learnathon.pdf as guided_analytics_learnathon.pdf\n",
      "Waiting 8 seconds to retrieve the next document.\n",
      "Downlading document: https://files.knime.com/sites/default/files/bigdataworkshop.pdf as bigdataworkshop.pdf\n"
     ]
    }
   ],
   "source": [
    "# Gather all links to the document\n",
    "collection = webpage.find_all('a')\n",
    "\n",
    "for item in collection:\n",
    "    if item.string == \"[PDF]\":\n",
    "        # Adding random wait time so we do not hammer the website needlessly\n",
    "        waitTime = randint(3,8)\n",
    "        print(\"Waiting \" + str(waitTime) + \" seconds to retrieve the next document.\")\n",
    "        sleep(waitTime)\n",
    "        doc_path = item['href']\n",
    "        dest_file = os.path.basename(doc_path)\n",
    "        print('Downlading document: ' + doc_path + \" as \" + dest_file)\n",
    "        with urllib.request.urlopen(doc_path) as in_resp, open(dest_file, 'wb') as out_file:\n",
    "            shutil.copyfileobj(in_resp, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_notify(\"The web scraping process has completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for the script: 0:04:02.337139\n"
     ]
    }
   ],
   "source": [
    "print ('Total time for the script:',(datetime.now() - startTimeScript))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
