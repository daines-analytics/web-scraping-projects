[{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Time Series Model for Monthly Armed Robberies in Boston Using Python","author":"David Lowe","date":"Wed, 23 Jan 2019 13:24:05 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/23\/time-series-model-for-monthly-armed-robberies-in-boston-using-python\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nCode Credit: Adapted from a blog post made available by Dr. Jason Brownlee of Machine Learning Mastery.\nPREFACE: This is a replication of Python code from Dr. Brownlee\u2019s blog post on time series. I have combined all the code snippets into one script so that I could turn the whole process into a template. The comments and analysis were also part of the blog post and annotated here to explain each coding block.\nSUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Armed Robberies in Boston dataset is a time series situation where we are trying to forecast future outcomes based on the past data points.\nINTRODUCTION: The problem is to predict the number of monthly armed robberies in Boston, USA. The dataset provides the number of monthly armed robberies in Boston from January 1966 to October 1975, Monthly Boston armed robberies Jan.1966-Oct.1975 Deutsch and Alt (1977) and credited to McCleary & Hay (1980).\nANALYSIS: The baseline prediction (or persistence) for the dataset resulted in an RMSE of 51.8. The manually configured model was simplified to ARIMA(0,1,2) and produced an RMSE of 49.8, which was slightly better than the persistent model. After applying the power transformation (Box-Cox) to the dataset, the final RMSE of the model on the transformed data was 49.4. This is only a slightly smaller error than the ARIMA model on untransformed data, and it may or may not be statistically different.\nCONCLUSION: The final RMSE for the validation period was predicted at 53 robberies, and it was not too different from the expected error of 49. Although the forecast appears to have the characteristic of a persistence forecast, this does suggest that, while this time series does have an obvious trend, it is still a reasonably difficult problem.\nDataset Used: Monthly Armed Robberies in Boston\nDataset ML Model: Time series forecast with numerical attributes\nDataset Reference: https:\/\/datamarket.com\/data\/set\/22ob\/monthly-boston-armed-robberies-jan1966-oct1975-deutsch-and-alt-1977#!ds=22ob&display=line\nOne potential source of performance benchmark: https:\/\/machinelearningmastery.com\/time-series-forecast-case-study-python-monthly-armed-robberies-boston\/\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"It\u2019s Your Turn","author":"David Lowe","date":"Tue, 22 Jan 2019 13:20:56 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/22\/its-your-turn\/","blog_text":"\n\t\t\t\t\nIn his podcast, Akimbo [https:\/\/www.akimbo.me\/], Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode. \n\n\n\nSeth dedicated this podcast to reading some of the passages in his book, What to Do When it\u2019s Your Turn (and it\u2019s Always Your Turn). If you like what Seth said in this podcast, I would highly recommend getting this book for the full experience.\n\n\n\nThe universe does not seek revenge on those who choose \u2013 Page 124Where do you put the tired? \u2013 Page 122Working the hallway \u2013 Page 123No place to hide \u2013 Page 114It\u2019s all invented (but that doesn\u2019t mean it isn\u2019t real) \u2013 Pages 90-91That story that keeps replaying \u2013 Page 91On living in two futures at once \u2013 Page 88Bravery and courage are for other people \u2013 Page 81\n\n\n\nSeth concluded the podcast with\u2026\n\n\n\n\u201cWhen I say to people, make a ruckus. What I\u2019m saying is that we each have the chance to see the world as it is and to choose the path that enables us to make a contribution, to connect dots instead of collect them, to make an assertion, to raise our hand, to contribute to show up and make things better. So, yeah, go make a ruckus.\u201d\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 4","author":"David Lowe","date":"Mon, 21 Jan 2019 13:29:55 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/21\/binary-classification-model-for-miniboone-particle-identification-using-r-take-4\/","blog_text":"\n\t\t\t\tTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\nFrom the previous iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\nFrom the previous iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\nFrom the previous iteration Take3, we examined the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\nIn the current iteration Take4, we will explore the Recursive Feature Elimination (or RFE) technique by recursively removing attributes and building a model on those attributes that remain.\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\nFrom the previous iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data.\nIn the current iteration Take4, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.79%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.??%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.??%, which was even better than the training data.\nFrom the model-building perspective, the number of attributes decreased by 10, from 50 down to 40 in iteration Take4. The processing time went from 17 hours 18 minutes in iteration Take1 down to 30 hours 58 minutes in Take3, which was an increase of 21.5% from Take1. It was a significant increase in comparison to Take2, which had a processing time of 12 hours 17 minutes. It was also a significant increase in comparison to Take3, which had a processing time of 6 hours 48 minutes.\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an increased processing time after running Recursive Feature Elimination. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\nDataset Used: MiniBooNE particle identification Data Set\nDataset ML Model: Binary classification with numerical attributes\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Merely Do It Blog Entries Using R","author":"David Lowe","date":"Sun, 20 Jan 2019 13:09:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/20\/web-scraping-of-merely-do-it-blog-entries-using-r\/","blog_text":"\n\t\t\t\t\nSUMMARY: The purpose of this project is to practice web\nscraping by gathering specific pieces of information from a website. The web\nscraping code was written in R and leveraged the rvest package.\n\n\n\nINTRODUCTION: David Lowe hosts his blog at merelydoit.blog.\nThe purpose of this exercise is to practice web scraping by gathering the blog\nentries from Merely Do It\u2019s RSS feed. This iteration of the script\nautomatically traverses the RSS feed to capture all entries from the blog site.\n\n\n\nStarting URLs: https:\/\/merelydoit.blog\/feed or\nhttps:\/\/merelydoit.blog\/feed\/?paged=1\n\n\n\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"10X\u7684\u7d93\u9a57","author":"David Lowe","date":"Sat, 19 Jan 2019 13:44:31 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/19\/10x%e7%9a%84%e7%b6%93%e9%a9%97\/","blog_text":"\n\t\t\t\t\uff08\u5f9e\u6211\u7684\u4e00\u500b\u559c\u6b61\u8207\u5c0a\u656c\u7684\u4f5c\u5bb6\uff0c\u8cfd\u65af \u9ad8\u6c40\uff09\n10X\u7a0b\u5e8f\u54e1\uff0c10X\u6230\u7565\u5c08\u5bb6\uff0c10X\u5916\u79d1\u91ab\u751f\u3002\n\u9019\u662f\u6211\u5011\u4e00\u76f4\u5728\u5c0b\u627e\u7684\u76ee\u6a19\u3002\u90a3\u4e9b\u662f\u5728\u4e0d\u540c\u6c34\u6e96\u4e0a\u64cd\u4f5c\u7684\u4eba\uff0c\u4ed6\u5011\u7684\u6210\u5c31\u80fd\u6539\u8b8a\u5176\u4ed6\u4e00\u5207\u7684\u5de5\u4f5c\u3002\n\u9019\u554f\u984c\u662f\uff1a1X\u8ca2\u737b\u8005\u53ea\u80fd\u901a\u904e\u52aa\u529b\u5de5\u4f5c\u5341\u500d\u4f46\u9084\u662f\u4e0d\u80fd\u6210\u70ba10X\u3002\u7576\u7136\uff0c\u6642\u9593\u7684\u9650\u5236\u4e5f\u4e0d\u6703\u4e0d\u5141\u8a31\uff0c\u9019\u4e5f\u662f\u56e0\u70ba10X\u8005\u4e0d\u662f\u5728\u540c\u4e00\u500b\u7d1a\u5225\u4e0a\u5de5\u4f5c\u3002\u9019\u4e0d\u662f\u66f4\u591a\u7684\u52aa\u529b\u80fd\u88dc\u511f\u7684\uff0c\u9019\u662f\u6709\u66f4\u591a\u7684\u6d1e\u5bdf\u529b\u3002\n\u70ba\u4e86\u5be6\u73fe\u9019\u7a2e\u524d\u9032\uff0c\u4f60\u9700\u8981\u76f8\u4fe1\u81ea\u5df1\u3002\u7d66\u4f60\u81ea\u5df2\u5275\u9020\u7a7a\u9593\u3002\u8b93\u7d00\u5f8b\u4f86\u62d2\u7d55\u8b93\u4f60\u56de\u52301X\u6a21\u5f0f\u7684\u5206\u5fc3\u3002\n10X\u8ca2\u737b\u8005\u5982\u6b64\u4e4b\u5c11\u7684\u539f\u56e0\u4e26\u4e0d\u662f\u6211\u5011\u7f3a\u4e4f\u5929\u8ce6\u3002\u9019\u662f\u56e0\u70ba\u6211\u5011\u7684\u7cfb\u7d71\u548c\u81ea\u6211\u5c0d\u8a71\u4f86\u5f15\u8a98\u6211\u5011\u76f8\u4fe1\u91cd\u89071X\u5de5\u4f5c\u5230\u75b2\u618a\u662f\u4e00\u689d\u66f4\u5b89\u5168\u7684\u9053\u8def\u3002\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using Python Take 3","author":"David Lowe","date":"Fri, 18 Jan 2019 13:58:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/18\/binary-classification-model-for-miniboone-particle-identification-using-python-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.58%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.95%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.85%, which was just slightly below than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.16%. Two algorithms (Bagged CART and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.92%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.82%, which was just slightly below the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 91.04%. Two algorithms (Random Forest and Stochastic Gradient Boosting) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.84%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was just slightly below the training data.\n\n\n\nFrom the model-building perspective, the number of attributes decreased by 23, from 50 down to 27 in iteration Take3. The processing time went from 7 hours 11 minutes in iteration Take1 down to 6 hours 22 minutes in Take3, which was a reduction of 11.3% from Take1. It was also a slight decrease in comparison to Take2, which had a processing time of 6 hours 33 minutes.\n\n\n\nCONCLUSION: For this iteration, the Stochastic Gradient Boosting algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting algorithm should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Drucker on Effective Decisions, Part 2","author":"David Lowe","date":"Thu, 17 Jan 2019 13:08:30 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/17\/drucker-on-effective-decisions-part-2\/","blog_text":"\n\t\t\t\tIn his book, The Essential Drucker: The Best of Sixty Years of Peter Drucker\u2019s Essential Writings on Management, Peter Drucker analyzed the ways that management practices and principles affect the performance of organizations, individuals, and society. The book covers the basic principles of management and gives professionals the tools to perform the tasks that the environment of tomorrow will require of them.\nThese are my takeaways from reading the book.\nIn the chapter \u201cEffective Decisions,\u201d Drucker discussed the five aspects of the effective decision-making process.\nStep 1. The decision-maker reaches a clear realization that the problem was a generic situation and not a random exception.\nStep 2. The decision-maker understand the specifications that the answer to the problem had to satisfy.\nStep 3. The decision-maker thinks through what is the \u201cright\u201d solution.\nStep 4. The decision-maker builds actions into the decision.\nStep 5. The decision-maker gathers feedback that tests the validity and effectiveness of the decision.\nIn Step 2, the decision-makers reach a clear understanding of \u201cspecification of the decision.\u201d The specification defines:\n\nthe objectives the decision must reach\nthe minimum goals the decision must attain\nthe conditions the decision must satisfy\n\nAnother word, an effective decision must satisfy the boundary conditions, in scientific term.\nIn addition to supporting decisions that are effective and appropriate, the boundary conditions also can help in other ways. Sometimes we might have reached a decision that satisfies the wrong boundary conditions. On those occasions, it is still possible to salvage the appropriate decision when we have incorrect boundary conditions. However, we will not be able to make the necessary correction on a decision that is inadequate to its specifications, to begin with.\nAlso, thinking clearly about the boundary conditions is necessary so that we know when a decision must be abandoned. Boundary conditions are, after all, risk-taking judgment calls.\nIn the end, Drucker suggested that thinking clearly about the boundary conditions is needed to identify the most dangerous of all possible decisions: the one that might work if nothing else goes wrong. These decisions always seem to make sense, but they often have boundary conditions that are grossly improbable. Effective decision-makers do not rely on miracles.\nEventually, everyone can and will make the wrong decision. But no one needs to make a decision that falls short of satisfying the boundary conditions or the specifications.\n\t\t\t\t\t\t\t"},{"blog_title":"Web Scraping of Machine Learning Mastery Blog Using R Take 2","author":"David Lowe","date":"Wed, 16 Jan 2019 13:48:45 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/16\/web-scraping-of-machine-learning-mastery-blog-using-r-take-2\/","blog_text":"\n\t\t\t\tSUMMARY: The purpose of this project is to practice web scraping by gathering specific pieces of information from a website. The web scraping code was written in R and leveraged the rvest package.\nINTRODUCTION: Dr. Jason Brownlee\u2019s Machine Learning Mastery hosts its tutorial lessons at https:\/\/machinelearningmastery.com\/blog. The purpose of this exercise is to practice web scraping by gathering the blog entries from Machine Learning Mastery\u2019s web pages. This iteration of the script automatically traverses the web pages to capture all blog entries and store all captured information in a JSON output file.\nStarting URLs: https:\/\/machinelearningmastery.com\/blog\nThe source code and JSON output can be found here on GitHub.\n\t\t\t\t\t\t\t"},{"blog_title":"Waiting for Godiva","author":"David Lowe","date":"Tue, 15 Jan 2019 13:59:43 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/15\/waiting-for-godiva\/","blog_text":"\n\t\t\t\tIn his podcast, Akimbo, Seth Godin teaches us how to adopt a posture of possibility, change the culture, and choose to make a difference. Here are my takeaways from the episode.\nIn this podcast, Seth discussed a startup experiment he did back in the early part of 2002-2003. The startup record label was ZoomTone, and it produced several soundtracks using the new Super Audio CD (SACD) format. The startup failed, and Seth learned an important lesson.\nIn many markets, the \u201cregular kind\u201d or the familiar genre is the kind that most people choose. For the SACD equipment purchasers, they did not purchase the equipment to listen to the new music that ZoomTone was producing. They purchased the equipment to listen to the music that they are already familiar. Listening to the familiar music, even on the brand-new technologies, requires less cognitive load and effort on people\u2019s part.\nVery often, we must work hard to find pockets of people who do not want the \u201cregular kind.\u201d They are the people who want the new kind, the challenging kind, or the experimental kind. Most people, even when they seek the new, do not want things that are drastically new.\nAs it turns out, most people are afraid, when they are asked to buy something or to commit. They are afraid of it might not work. They are afraid of what other people will say. They\u2019re afraid of feeling stupid because they wasted their time or their money.\nEventually, the culture changes or moves from one place to another. If our job is to change the culture, we must make sure we recognize who \u201cthe people like us\u201d are. The culture is the culture, and it does what it does. We rarely are in the position to decide how and when the culture will change.\nAs changemakers, what we can do right now is find those little pockets of the culture. Those little pockets have the smallest viable audience. We can embrace them, see them for who they are, and give them what they dream of being or doing. More importantly, we can work hard to can give them the emotions, the feelings, the status that they seek. At the same time, make it easy for them to tell their friends about the change we are trying to make.\n\t\t\t\t\t\t\t"},{"blog_title":"Binary Classification Model for MiniBooNE Particle Identification Using R Take 3","author":"David Lowe","date":"Mon, 14 Jan 2019 13:47:48 +0000","blog_url":"https:\/\/merelydoit.blog\/2019\/01\/14\/binary-classification-model-for-miniboone-particle-identification-using-r-take-3\/","blog_text":"\n\t\t\t\t\nTemplate Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery.\n\n\n\nSUMMARY: The purpose of this project is to construct a prediction model using various machine learning algorithms and to document the end-to-end steps using a template. The MiniBooNE Particle Identification dataset is a classic binary classification situation where we are trying to predict one of the two possible outcomes.\n\n\n\nINTRODUCTION: This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). The data file is set up as follows. In the first line is the number of signal events followed by the number of background events. The records with the signal events come first, followed by the background events. Each line, after the first line, has the 50 particle ID variables for one event.\n\n\n\nIn iteration Take1, the script focused on evaluating various machine learning algorithms and identifying the model that produces the best overall metrics. Iteration Take1 established the baseline performance for accuracy and processing time.\n\n\n\nIn iteration Take2, we examined the feature selection technique of eliminating collinear features. By eliminating the collinear features, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iteration Take1.\n\n\n\nFor this iteration, we will examine the feature selection technique of attribute importance ranking. By taking only the most important attributes, we hoped to decrease the processing time and maintain a similar level of accuracy compared to iterations Take1 and Take2.\n\n\n\nANALYSIS: From the previous iteration Take1, the baseline performance of the eight algorithms achieved an average accuracy of 90.82%. Two algorithms (Bagged CART and Random Forest) achieved the top accuracy scores after the first round of modeling. After a series of tuning trials, Random Forest turned in the top result using the training data. It achieved an average accuracy of 93.74%. By optimizing the tuning parameters, the Random Forest algorithm processed the testing dataset with an accuracy of 93.91%, which was even better than the training data.\n\n\n\nFrom the previous iteration Take2, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.04%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Stochastic Gradient Boosting turned in the top overall result and achieved an accuracy metric of 93.47%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.57%, which was even better than the training data.\n\n\n\nIn the current iteration Take3, the baseline performance of the machine learning algorithms achieved an average accuracy of 90.49%. Two algorithms (Stochastic Gradient Boosting and Random Forest) achieved the top accuracy metrics after the first round of modeling. After a series of tuning trials, Random Forest turned in the top overall result and achieved an accuracy metric of 93.52%. By using the optimized parameters, the Stochastic Gradient Boosting algorithm processed the testing dataset with an accuracy of 93.74%, which was even better than the training data. From the model-building perspective, the number of attributes decreased by 25, from 50 down to 25 in iteration Take3. The processing time went from 17 hours 18 minutes in iteration Take1 down to 6 hours 48 minutes in Take3, which was a reduction of 60.6% from Take1. It was also a significant decrease in comparison to Take2, which had a processing time of 12 hours 17 minutes.\n\n\n\nCONCLUSION: For this iteration, the Random Forest algorithm achieved the best overall results with an improved processing time after eliminating the unimportant features. For this dataset, the Stochastic Gradient Boosting and Random Forest algorithms should be considered for further modeling or production use.\n\n\n\nDataset Used: MiniBooNE particle identification Data Set\n\n\n\nDataset ML Model: Binary classification with numerical attributes\n\n\n\nDataset Reference: https:\/\/archive.ics.uci.edu\/ml\/datasets\/MiniBooNE+particle+identification\n\n\n\nThe HTML formatted report can be found here on GitHub.\n\t\t\t\t\t\t\t"}]