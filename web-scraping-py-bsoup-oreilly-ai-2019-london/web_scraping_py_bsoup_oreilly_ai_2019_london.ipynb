{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "web-scraping-py-bsoup-oreilly-ai-2019-london.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4mr2mbWYoOa",
        "colab_type": "text"
      },
      "source": [
        "# Web Scraping of O'Reilly Artificial Intelligence Conference 2019 London\n",
        "### David Lowe\n",
        "### December 6, 2019\n",
        "\n",
        "SUMMARY: The purpose of this project is to practice web scraping by extracting specific pieces of information from a website. The web scraping Python code leverages the BeautifulSoup module.\n",
        "\n",
        "INTRODUCTION: The O’Reilly Artificial Intelligence (AI) Conference covers the full range of topics in leveraging the AI technologies for developing software applications and creating innovative solutions. This web scraping script will automatically traverse through the entire web page and collect all links to the PDF and PPTX documents. The script will also download the documents as part of the scraping process. The Python script ran in the Google Colaboratory environment and can be adapted to run in any Python environment without the Colab-specific configuration.\n",
        "\n",
        "Starting URLs: https://conferences.oreilly.com/artificial-intelligence/ai-eu/public/schedule/proceedings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyLL5BLJYoOc",
        "colab_type": "text"
      },
      "source": [
        "## Loading Libraries and Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wELc-r0BaiDC",
        "colab_type": "code",
        "outputId": "69680819-0560-4532-869f-6bce888176a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Refresh package repositories and set up additional Linux and Python packages\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!pip install -q pymysql selenium"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Connecting to\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Connecting to\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.174)\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [564 B]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.174)\r                                                                               \rGet:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.174)\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.174)\r                                                                               \rGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [74.7 kB]\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [138 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [26.0 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:17 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,728 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [786 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,312 kB]\n",
            "Get:20 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [833 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [735 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,031 kB]\n",
            "Fetched 6,938 kB in 4s (1,615 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension adobe-flashplugin\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 71.9 MB of archives.\n",
            "After this operation, 257 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 78.0.3904.97-0ubuntu0.18.04.1 [1,078 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 78.0.3904.97-0ubuntu0.18.04.1 [63.3 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 78.0.3904.97-0ubuntu0.18.04.1 [3,074 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 78.0.3904.97-0ubuntu0.18.04.1 [4,464 kB]\n",
            "Fetched 71.9 MB in 8s (8,528 kB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 134923 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_78.0.3904.97-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (78.0.3904.97-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_78.0.3904.97-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (78.0.3904.97-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_78.0.3904.97-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (78.0.3904.97-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_78.0.3904.97-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (78.0.3904.97-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (78.0.3904.97-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Setting up chromium-browser (78.0.3904.97-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (78.0.3904.97-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (78.0.3904.97-0ubuntu0.18.04.1) ...\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 911kB 14.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tGlgDPeYoOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import smtplib\n",
        "import sys\n",
        "from email.message import EmailMessage\n",
        "from datetime import datetime\n",
        "import requests\n",
        "from requests.exceptions import HTTPError\n",
        "from requests.exceptions import ConnectionError\n",
        "from bs4 import BeautifulSoup\n",
        "from random import randint\n",
        "from time import sleep\n",
        "from selenium import webdriver\n",
        "import pymysql\n",
        "\n",
        "startTimeScript = datetime.now()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxJqydfiYoOg",
        "colab_type": "text"
      },
      "source": [
        "## Setting up the basic functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fnlwzz-PYoOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def email_notify(msg_text):\n",
        "    sender = os.environ.get('MAIL_SENDER')\n",
        "    receiver = os.environ.get('MAIL_RECEIVER')\n",
        "    gateway = os.environ.get('SMTP_GATEWAY')\n",
        "    smtpuser = os.environ.get('SMTP_USERNAME')\n",
        "    password = os.environ.get('SMTP_PASSWORD')\n",
        "    if sender==None or receiver==None or gateway==None or smtpuser==None or password==None:\n",
        "        sys.exit(\"Incomplete email setup info. Script Processing Aborted!!!\")\n",
        "    msg = EmailMessage()\n",
        "    msg.set_content(msg_text)\n",
        "    msg['Subject'] = 'Notification from Python Web Scraping Script'\n",
        "    msg['From'] = sender\n",
        "    msg['To'] = receiver\n",
        "    server = smtplib.SMTP(gateway, 587)\n",
        "    server.starttls()\n",
        "    server.login(smtpuser, password)\n",
        "    server.send_message(msg)\n",
        "    server.quit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk6cDbhzqgsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_file(doc_path):\n",
        "#    local_file = os.path.basename(doc_path)\n",
        "    local_file = doc_path.split('/')[-1]\n",
        "    gdrivePrefix = '/content/gdrive/My Drive/Colab_Downloads/'\n",
        "    dest_file = gdrivePrefix + local_file\n",
        "    with requests.get(doc_path, stream=True) as r:\n",
        "        with open(dest_file, 'wb') as f:\n",
        "            shutil.copyfileobj(r.raw, f)\n",
        "    print('Downladed file: ' + dest_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF4hTJ_jYoOn",
        "colab_type": "text"
      },
      "source": [
        "## Setting up the necessary parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy-XtBEiZwdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up the verbose flag to print detailed messages for debugging (setting True will activate!)\n",
        "verbose = False\n",
        "\n",
        "# Set up the sendNotification flag to send progress emails (setting True will send emails!)\n",
        "sendNotification = False\n",
        "\n",
        "# Set up the mountStorage flag to mount G Drive for storing files (setting True will mount the drive!)\n",
        "mountStorage = True\n",
        "\n",
        "# Set up the executeDownload flag to download files (setting True will download!)\n",
        "executeDownload = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2LZP6EpiqRL",
        "colab_type": "code",
        "outputId": "db3a4f97-9943-46c2-f004-f1fc9b6f41ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "# Mount Google Drive locally for storing files\n",
        "\n",
        "if (mountStorage):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak_tp8PIabC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if (sendNotification): email_notify(\"The web scraping process has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntjQrml7YoOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specifying the URL of desired web page to be scrapped\n",
        "startingURL = \"https://conferences.oreilly.com/artificial-intelligence/ai-eu/public/schedule/proceedings\"\n",
        "websiteURL = \"\"\n",
        "\n",
        "# Creating an html document from the URL\n",
        "uastring = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:70.0) Gecko/20100101 Firefox/70.0\"\n",
        "headers={'User-Agent': uastring}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWf3Y7c3YoOs",
        "colab_type": "text"
      },
      "source": [
        "## Performing the Scraping and Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0TO1zBrYoOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if (sendNotification): email_notify(\"The web page loading and item extraction process has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX6dpqjie69M",
        "colab_type": "code",
        "outputId": "e6831c47-2bc1-4991-e377-0a71d373d875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "try:\n",
        "    s = requests.Session()\n",
        "    resp = s.get(startingURL, headers=headers)\n",
        "    if (verbose): print(resp.text)\n",
        "except HTTPError as e:\n",
        "    print('The server could not serve up the web page!')\n",
        "    sys.exit(\"Script processing cannot continue!!!\")\n",
        "except ConnectionError as e:\n",
        "    print('The server could not be reached due to connection issues!')\n",
        "    sys.exit(\"Script processing cannot continue!!!\")\n",
        "\n",
        "if (resp.status_code==requests.codes.ok):\n",
        "    print('Successfully accessed the web page: ' + startingURL)\n",
        "    webPage = BeautifulSoup(resp.text, 'lxml')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully accessed the web page: https://conferences.oreilly.com/artificial-intelligence/ai-eu/public/schedule/proceedings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk9gY0vwYoOv",
        "colab_type": "code",
        "outputId": "8251f81a-0279-45eb-812e-e86e64b39635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Gather all links to the document\n",
        "collection = webPage.find_all(\"a\")\n",
        "i = 0\n",
        "\n",
        "for item in collection:\n",
        "    if (verbose): print(item)\n",
        "    docPath = item['href']\n",
        "    if docPath.lower().endswith(\".pdf\") | docPath.lower().endswith(\".pptx\") | docPath.lower().endswith(\".zip\"):\n",
        "        i = i + 1\n",
        "        docPath = websiteURL + docPath\n",
        "        # Adding random wait time so we do not hammer the website needlessly\n",
        "        waitTime = randint(2,5)\n",
        "        print(\"Waiting \" + str(waitTime) + \" seconds to retrieve \" + docPath)\n",
        "        sleep(waitTime)\n",
        "        if (executeDownload): download_file(docPath)\n",
        "\n",
        "print('Finished finding all available documents on the web page!')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Waiting 5 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/About%20Space%20Invaders%20and%20automated%20scaling%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/About%20Space%20Invaders%20and%20automated%20scaling%20Presentation.pdf\n",
            "Waiting 2 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Adversarial%20network%20for%20natural%20language%20synthesis%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Adversarial%20network%20for%20natural%20language%20synthesis%20Presentation.pdf\n",
            "Waiting 5 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/AI%20for%20financial%20time%20series%20forecasting%20and%20dynamic%20assets%20portfolio%20optimization%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/AI%20for%20financial%20time%20series%20forecasting%20and%20dynamic%20assets%20portfolio%20optimization%20Presentation.pdf\n",
            "Waiting 3 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Anomaly%20detection%20in%20smart%20buildings%20using%20federated%20learning%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Anomaly%20detection%20in%20smart%20buildings%20using%20federated%20learning%20Presentation.pdf\n",
            "Waiting 4 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Audience%20projection%20of%20target%20consumers%20over%20multiple%20domains_%20A%20NER%20and%20Bayesian%20approach%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Audience%20projection%20of%20target%20consumers%20over%20multiple%20domains_%20A%20NER%20and%20Bayesian%20approach%20Presentation.pdf\n",
            "Waiting 2 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Audience%20projection%20of%20target%20consumers%20over%20multiple%20domains_%20A%20NER%20and%20Bayesian%20approach%20Presentation%201.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Audience%20projection%20of%20target%20consumers%20over%20multiple%20domains_%20A%20NER%20and%20Bayesian%20approach%20Presentation%201.pdf\n",
            "Waiting 5 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Building%20and%20deploying%20AI%20applications%20and%20systems%20at%20scale%20Presentation%201.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Building%20and%20deploying%20AI%20applications%20and%20systems%20at%20scale%20Presentation%201.pdf\n",
            "Waiting 2 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Building%20contextual%20AI%20assistants%20with%20machine%20learning%20and%20open%20source%20tools%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Building%20contextual%20AI%20assistants%20with%20machine%20learning%20and%20open%20source%20tools%20Presentation.pdf\n",
            "Waiting 4 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Containerized%20architectures%20for%20deep%20learning%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Containerized%20architectures%20for%20deep%20learning%20Presentation.pdf\n",
            "Waiting 2 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Creating%20smaller%2C%20faster%2C%20production-worthy%20mobile%20machine%20learning%20models%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Creating%20smaller%2C%20faster%2C%20production-worthy%20mobile%20machine%20learning%20models%20Presentation.pdf\n",
            "Waiting 5 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Deep%20learning%20with%20Horovod%20and%20Spark%20using%20GPUs%20and%20Docker%20containers%20Presentation.pptx\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Deep%20learning%20with%20Horovod%20and%20Spark%20using%20GPUs%20and%20Docker%20containers%20Presentation.pptx\n",
            "Waiting 5 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Deploying%20machine%20learning%20models%20on%20the%20edge%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Deploying%20machine%20learning%20models%20on%20the%20edge%20Presentation.pdf\n",
            "Waiting 2 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Executive%20Briefing_%20A%20look%20at%20the%20future%20of%20online%20pricing%20and%20algorithm-led%20collusion%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Executive%20Briefing_%20A%20look%20at%20the%20future%20of%20online%20pricing%20and%20algorithm-led%20collusion%20Presentation.pdf\n",
            "Waiting 2 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Executive%20Briefing_%20Advances%20in%20privacy%20for%20machine%20learning%20systems%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Executive%20Briefing_%20Advances%20in%20privacy%20for%20machine%20learning%20systems%20Presentation.pdf\n",
            "Waiting 4 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Executive%20Briefing_%20From%20laggard%20to%20leader%E2%80%94Winning%20the%20AI%20race%20Presentation.pptx\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Executive%20Briefing_%20From%20laggard%20to%20leader%E2%80%94Winning%20the%20AI%20race%20Presentation.pptx\n",
            "Waiting 3 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Executive%20Briefing_%20Fusing%20data%20and%20design%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Executive%20Briefing_%20Fusing%20data%20and%20design%20Presentation.pdf\n",
            "Waiting 5 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Executive%20Briefing_%20How%20the%20growth%20of%20voice-based%20AI%20stands%20to%20blur%20the%20lines%20of%20big%20data%20Presentation.pptx\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Executive%20Briefing_%20How%20the%20growth%20of%20voice-based%20AI%20stands%20to%20blur%20the%20lines%20of%20big%20data%20Presentation.pptx\n",
            "Waiting 5 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Executive%20Briefing_%20Will%20you%20learn%20Chinese%20to%20advance%20in%20AI_%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Executive%20Briefing_%20Will%20you%20learn%20Chinese%20to%20advance%20in%20AI_%20Presentation.pdf\n",
            "Waiting 4 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/For%20AI%20to%20thrive%2C%20failure%20is%20necessary_%20A%20practical%20guide%20_sponsored%20by%20IBM%20Watson_%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/For%20AI%20to%20thrive%2C%20failure%20is%20necessary_%20A%20practical%20guide%20_sponsored%20by%20IBM%20Watson_%20Presentation.pdf\n",
            "Waiting 2 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/How%20to%20deploy%20large-scale%20distributed%20data%20analytics%20and%20machine%20learning%20on%20containers%20_sponsored%20by%20HPE_%20Presentation.pptx\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/How%20to%20deploy%20large-scale%20distributed%20data%20analytics%20and%20machine%20learning%20on%20containers%20_sponsored%20by%20HPE_%20Presentation.pptx\n",
            "Waiting 5 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Implementing%20an%20AI%20multicloud%20broker%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Implementing%20an%20AI%20multicloud%20broker%20Presentation.pdf\n",
            "Waiting 4 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Large-scale%20machine%20learning%20at%20Facebook_%20Implications%20of%20platform%20design%20on%20developer%20productivity%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Large-scale%20machine%20learning%20at%20Facebook_%20Implications%20of%20platform%20design%20on%20developer%20productivity%20Presentation.pdf\n",
            "Waiting 4 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Machine%20learning%20challenges%20at%20LinkedIn_%20Spark%2C%20TensorFlow%2C%20and%20beyond%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Machine%20learning%20challenges%20at%20LinkedIn_%20Spark%2C%20TensorFlow%2C%20and%20beyond%20Presentation.pdf\n",
            "Waiting 2 seconds to retrieve https://deepracing.io/assets/presentations/OReilly_LyndonLeggate_DeepRacer.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/OReilly_LyndonLeggate_DeepRacer.pdf\n",
            "Waiting 5 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/NLP%20for%20healthcare_%20Feature%20engineering%20and%20model%20diagnostics%20Presentation.pptx\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/NLP%20for%20healthcare_%20Feature%20engineering%20and%20model%20diagnostics%20Presentation.pptx\n",
            "Waiting 3 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/NLP%20for%20healthcare_%20Feature%20engineering%20and%20model%20diagnostics%20Presentation%201.pptx\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/NLP%20for%20healthcare_%20Feature%20engineering%20and%20model%20diagnostics%20Presentation%201.pptx\n",
            "Waiting 2 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/NLP%20for%20healthcare_%20Feature%20engineering%20and%20model%20diagnostics%20Presentation%202.pptx\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/NLP%20for%20healthcare_%20Feature%20engineering%20and%20model%20diagnostics%20Presentation%202.pptx\n",
            "Waiting 5 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Public%20policy%20and%20deep%20reinforcement%20learning%20on%20AWS%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Public%20policy%20and%20deep%20reinforcement%20learning%20on%20AWS%20Presentation.pdf\n",
            "Waiting 5 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Real-time%20AI%20for%20entity%20resolution%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Real-time%20AI%20for%20entity%20resolution%20Presentation.pdf\n",
            "Waiting 4 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/ROCm%20and%20Hopsworks%20for%20end-to-end%20deep%20learning%20pipelines%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/ROCm%20and%20Hopsworks%20for%20end-to-end%20deep%20learning%20pipelines%20Presentation.pdf\n",
            "Waiting 5 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Scalable%20AI%20and%20reinforcement%20learning%20with%20Ray%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Scalable%20AI%20and%20reinforcement%20learning%20with%20Ray%20Presentation.pdf\n",
            "Waiting 2 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Start%20your%20engines_%20Making%20deep%20reinforcement%20learning%20accessible%20to%20all%20developers%20_sponsored%20by%20AWS_%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Start%20your%20engines_%20Making%20deep%20reinforcement%20learning%20accessible%20to%20all%20developers%20_sponsored%20by%20AWS_%20Presentation.pdf\n",
            "Waiting 5 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/TFX_%20Production%20ML%20pipelines%20with%20TensorFlow%20Presentation%201.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/TFX_%20Production%20ML%20pipelines%20with%20TensorFlow%20Presentation%201.pdf\n",
            "Waiting 4 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/TFX_%20Production%20ML%20pipelines%20with%20TensorFlow%20Presentation%202.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/TFX_%20Production%20ML%20pipelines%20with%20TensorFlow%20Presentation%202.pdf\n",
            "Waiting 2 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/The%20power%20of%20knowledge%20at%20scale%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/The%20power%20of%20knowledge%20at%20scale%20Presentation.pdf\n",
            "Waiting 4 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/The%20quest%20for%20high-quality%20data%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/The%20quest%20for%20high-quality%20data%20Presentation.pdf\n",
            "Waiting 4 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/Unlocking%20data%20capital%20with%20AI%20_sponsored%20by%20Dell_%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/Unlocking%20data%20capital%20with%20AI%20_sponsored%20by%20Dell_%20Presentation.pdf\n",
            "Waiting 5 seconds to retrieve https://cdn.oreillystatic.com/en/assets/1/event/299/When%20flying%20is%20cheaper%20than%20standing%20still%20Presentation.pdf\n",
            "Downladed file: /content/gdrive/My Drive/Colab_Downloads/When%20flying%20is%20cheaper%20than%20standing%20still%20Presentation.pdf\n",
            "Finished finding all available documents on the web page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_t7A3eOYoOy",
        "colab_type": "code",
        "outputId": "950a61ba-fe17-44ff-b0cb-7bf888682335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Number of documents processed:', i)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of documents processed: 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aptSJkHZbc_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if (sendNotification): email_notify(\"The web scraping process has completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN6rWf7qYoO1",
        "colab_type": "code",
        "outputId": "80a576af-65ea-41ca-b417-42c5a93ce5b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print ('Total time for the script:',(datetime.now() - startTimeScript))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total time for the script: 0:03:16.701618\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}